{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBTrACS Tropical Cyclone Data with pystac-monty\n",
    "\n",
    "This notebook demonstrates how to use pystac-monty to process IBTrACS (International Best Track Archive for Climate Stewardship) tropical cyclone data and visualize it using interactive maps. We'll:\n",
    "\n",
    "1. Download the IBTrACS tropical cyclone dataset\n",
    "2. Convert the data to STAC items using pystac-monty\n",
    "3. Display events on an interactive map\n",
    "4. Allow selection of events to view related hazards\n",
    "5. Explore the Monty STAC model and its metadata\n",
    "\n",
    "Let's begin by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Visualization libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# STAC and pystac-monty\n",
    "import pytz\n",
    "from pystac_monty.extension import MontyExtension\n",
    "from pystac_monty.geocoding import WorldAdministrativeBoundariesGeocoder\n",
    "from pystac_monty.sources.ibtracs import IBTrACSDataSource, IBTrACSTransformer\n",
    "\n",
    "# Import STAC helper functions\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from stac_helpers import (\n",
    "    check_stac_api_availability,\n",
    "    check_collection_exists,\n",
    "    create_collection_from_file,\n",
    "    create_collection_fallback,\n",
    "    add_items_to_collection,\n",
    "    delete_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Process IBTrACS Data\n",
    "\n",
    "First, let's download the IBTrACS dataset and initialize the data source and transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define IBTrACS dataset URL (using the North Atlantic basin as an example)\n",
    "ibtracs_url = \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/csv/ibtracs.NA.list.v04r00.csv\"\n",
    "\n",
    "# # Download the dataset\n",
    "# print(f\"Downloading IBTrACS dataset from {ibtracs_url}...\")\n",
    "# response = requests.get(ibtracs_url)\n",
    "# print(f\"Downloaded {len(response.content) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# read csv file\n",
    "with open('/home/emathot/Downloads/ibtracs.NA.list.v04r00.csv', 'r') as file:\n",
    "    response = file.read()\n",
    "\n",
    "# Initialize the data source and transformer\n",
    "data_source = IBTrACSDataSource(ibtracs_url, response)\n",
    "\n",
    "# Initialize the geocoder\n",
    "geocoder = WorldAdministrativeBoundariesGeocoder(\"../tests/data-files/world-administrative-boundaries.fgb\")\n",
    "transformer = IBTrACSTransformer(data_source, geocoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create STAC Items from IBTrACS Data\n",
    "\n",
    "Now, let's transform the IBTrACS data into STAC items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pystac_monty.validators.ibtracs:Invalid SID\n",
      "ERROR:pystac_monty.validators.ibtracs:Invalid basin code.\n",
      "ERROR:pystac_monty.sources.ibtracs:Failed to process ibtracs\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emathot/Workspace/IFRCGo/pystac-monty/pystac_monty/sources/ibtracs.py\", line 79, in get_stac_items\n",
      "    storm_data = parse_row_data(storm_data)\n",
      "  File \"/home/emathot/Workspace/IFRCGo/pystac-monty/pystac_monty/sources/ibtracs.py\", line 75, in parse_row_data\n",
      "    obj = IBTracsdataValidator(**row)\n",
      "  File \"/home/emathot/Workspace/IFRCGo/pystac-monty/.venv/lib/python3.10/site-packages/pydantic/main.py\", line 214, in __init__\n",
      "    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "pydantic_core._pydantic_core.ValidationError: 4 validation errors for IBTracsdataValidator\n",
      "ISO_TIME\n",
      "  Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing, input_value=' ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/datetime_from_date_parsing\n",
      "LAT\n",
      "  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='degrees_north', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/float_parsing\n",
      "LON\n",
      "  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='degrees_east', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/float_parsing\n",
      "DIST2LAND\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='km', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating STAC items from IBTrACS data...\n",
      "Created 3654 STAC items\n"
     ]
    }
   ],
   "source": [
    "# Create STAC items\n",
    "print(\"Creating STAC items from IBTrACS data...\")\n",
    "all_stac_items = list(transformer.get_stac_items())\n",
    "print(f\"Created {len(all_stac_items)} STAC items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 59, Hazards: 3595\n"
     ]
    }
   ],
   "source": [
    "# Separate the STAC items by role\n",
    "event_items = []\n",
    "hazard_items = []\n",
    "\n",
    "for item in all_stac_items:\n",
    "    # Filter for recent events (e.g., last 5 years)\n",
    "    if item.datetime and item.datetime.year < datetime.now().year - 5:\n",
    "        continue\n",
    "\n",
    "    roles = item.properties.get(\"roles\", [])\n",
    "    if \"event\" in roles:\n",
    "        event_items.append(item)\n",
    "    elif \"hazard\" in roles:\n",
    "        hazard_items.append(item)\n",
    "\n",
    "print(f\"Events: {len(event_items)}, Hazards: {len(hazard_items)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading STAC Items into a STAC API using the Transaction API\n",
    "\n",
    "Now that we have created STAC items from the IBTrACS data, let's load them into a STAC API using the transaction API. The transaction API allows us to create, update, and delete STAC items in a STAC API.\n",
    "\n",
    "We'll use the predefined collections from the monty-stac-extension examples folder:\n",
    "- ibtracs-events: For event items\n",
    "- ibtracs-hazards: For hazard items\n",
    "\n",
    "If these collections don't exist in the STAC API, we'll create them based on the predefined collection definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAC API is available at https://montandon-eoapi-stage.ifrc.org/stac\n"
     ]
    }
   ],
   "source": [
    "# Define the STAC API endpoint\n",
    "# Replace with your actual STAC API endpoint\n",
    "stac_api_url = \"https://montandon-eoapi-stage.ifrc.org/stac\"\n",
    "\n",
    "# Define the collection IDs for each type of item\n",
    "# These match the predefined collections in monty-stac-extension/examples\n",
    "event_collection_id = \"ibtracs-events\"\n",
    "hazard_collection_id = \"ibtracs-hazards\"\n",
    "\n",
    "# Define paths to the predefined collection definitions\n",
    "event_collection_path = \"../monty-stac-extension/examples/ibtracs-events/ibtracs-events.json\"\n",
    "hazard_collection_path = \"../monty-stac-extension/examples/ibtracs-hazards/ibtracs-hazards.json\"\n",
    "\n",
    "# Check if the STAC API is available\n",
    "api_available = check_stac_api_availability(stac_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'ibtracs-events' exists in the STAC API\n",
      "Collection 'ibtracs-hazards' exists in the STAC API\n"
     ]
    }
   ],
   "source": [
    "# Check if the collections exist and create them if they don't\n",
    "if api_available:\n",
    "    # Check and create event collection if needed\n",
    "    # delete_collection(stac_api_url, event_collection_id)\n",
    "    event_collection_exists = check_collection_exists(stac_api_url, event_collection_id)\n",
    "    if not event_collection_exists:\n",
    "        print(f\"\\nAttempting to create collection '{event_collection_id}'...\")\n",
    "        event_collection_created = create_collection_from_file(stac_api_url, event_collection_path)\n",
    "        if not event_collection_created:\n",
    "            print(\"Trying fallback method to create event collection...\")\n",
    "            event_collection_created = create_collection_fallback(\n",
    "                stac_api_url, \n",
    "                event_collection_id, \n",
    "                \"IBTrACS tropical cyclone events processed with pystac-monty\",\n",
    "                [\"event\", \"source\"]\n",
    "            )\n",
    "        event_collection_exists = event_collection_created\n",
    "    \n",
    "    # Check and create hazard collection if needed\n",
    "    # delete_collection(stac_api_url, hazard_collection_id)\n",
    "    hazard_collection_exists = check_collection_exists(stac_api_url, hazard_collection_id)\n",
    "    if not hazard_collection_exists:\n",
    "        print(f\"\\nAttempting to create collection '{hazard_collection_id}'...\")\n",
    "        hazard_collection_created = create_collection_from_file(stac_api_url, hazard_collection_path)\n",
    "        if not hazard_collection_created:\n",
    "            print(\"Trying fallback method to create hazard collection...\")\n",
    "            hazard_collection_created = create_collection_fallback(\n",
    "                stac_api_url, \n",
    "                hazard_collection_id, \n",
    "                \"IBTrACS tropical cyclone hazards processed with pystac-monty\",\n",
    "                [\"hazard\", \"source\"]\n",
    "            )\n",
    "        hazard_collection_exists = hazard_collection_created\n",
    "    \n",
    "    if not (event_collection_exists and hazard_collection_exists):\n",
    "        print(\"\\nWarning: One or more collections could not be created in the STAC API.\")\n",
    "        print(\"Some items may not be added to the STAC API.\")\n",
    "else:\n",
    "    print(\"STAC API is not available. Skipping collection checks and creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Adding event items to the collection...\n",
      "Processing batch 1 of 1 (59 items)\n",
      "Item 2021239N17281 already exists in the collection\n",
      "Added 59 items successfully, 0 items failed\n",
      "\n",
      "Adding hazard items to the collection...\n",
      "Processing batch 1 of 4 (1000 items)\n",
      "Item 2021239N17281-hazard-20210826T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210826T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210826T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210826T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210827T232500Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210828T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T165500Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210829T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210830T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210831T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210901T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210902T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T180000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210903T210000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T000000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T030000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T060000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T090000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T120000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T150000Z already exists in the collection\n",
      "Item 2021239N17281-hazard-20210904T180000Z already exists in the collection\n",
      "Processing batch 2 of 4 (1000 items)\n",
      "Processing batch 3 of 4 (1000 items)\n",
      "Processing batch 4 of 4 (595 items)\n",
      "Added 3595 items successfully, 0 items failed\n",
      "\n",
      "Summary: Added 3654 items successfully, 0 items failed\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Import STAC helper functions\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from stac_helpers import (\n",
    "    check_stac_api_availability,\n",
    "    check_collection_exists,\n",
    "    create_collection_from_file,\n",
    "    create_collection_fallback,\n",
    "    add_items_to_collection,\n",
    "    delete_collection\n",
    ")\n",
    "\n",
    "# Add the items to their respective collections if the API is available\n",
    "if api_available:\n",
    "    if event_collection_exists:\n",
    "        print(\"Adding event items to the collection...\")\n",
    "        event_success, event_failed = add_items_to_collection(stac_api_url, event_collection_id, event_items, overwrite=True)\n",
    "    else:\n",
    "        print(\"Skipping adding event items because the collection doesn't exist\")\n",
    "        event_success, event_failed = 0, len(event_items)\n",
    "    \n",
    "    if hazard_collection_exists:\n",
    "        print(\"\\nAdding hazard items to the collection...\")\n",
    "        hazard_success, hazard_failed = add_items_to_collection(stac_api_url, hazard_collection_id, hazard_items, overwrite=True)\n",
    "    else:\n",
    "        print(\"Skipping adding hazard items because the collection doesn't exist\")\n",
    "        hazard_success, hazard_failed = 0, len(hazard_items)\n",
    "    \n",
    "    total_success = event_success + hazard_success\n",
    "    total_failed = event_failed + hazard_failed\n",
    "    \n",
    "    print(f\"\\nSummary: Added {total_success} items successfully, {total_failed} items failed\")\n",
    "else:\n",
    "    print(\"Skipping adding items to collections because the API is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze IBTrACS Data\n",
    "\n",
    "Let's analyze the IBTrACS data to get a better understanding of the tropical cyclones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>correlation_id</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>hazard_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2023321N15278</td>\n",
       "      <td>Tropical Cyclone NOT_NAMED</td>\n",
       "      <td>2023-11-16T18:00:00+00:00</td>\n",
       "      <td>2023-11-18T00:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone NOT_NAMED (2023) in the North...</td>\n",
       "      <td>tropical cyclone, tropical depression, NOT_NAM...</td>\n",
       "      <td>20231116T180000-XYZ-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2023297N11277</td>\n",
       "      <td>Tropical Cyclone NOT_NAMED</td>\n",
       "      <td>2023-10-23T12:00:00+00:00</td>\n",
       "      <td>2023-10-24T12:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone NOT_NAMED (2023) in the North...</td>\n",
       "      <td>tropical cyclone, tropical depression, NOT_NAM...</td>\n",
       "      <td>20231023T120000-NIC-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>NIC</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2023292N13309</td>\n",
       "      <td>Tropical Cyclone TAMMY</td>\n",
       "      <td>2023-10-18T18:00:00+00:00</td>\n",
       "      <td>2023-10-31T18:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone TAMMY (2023) in the North Atl...</td>\n",
       "      <td>tropical cyclone, hurricane, TAMMY, 2023, Nort...</td>\n",
       "      <td>20231018T180000-ATG-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>ATG</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023284N10330</td>\n",
       "      <td>Tropical Cyclone SEAN</td>\n",
       "      <td>2023-10-10T18:00:00+00:00</td>\n",
       "      <td>2023-10-16T18:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone SEAN (2023) in the North Atla...</td>\n",
       "      <td>tropical cyclone, tropical storm, SEAN, 2023, ...</td>\n",
       "      <td>20231010T180000-XYZ-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2023271N16316</td>\n",
       "      <td>Tropical Cyclone RINA</td>\n",
       "      <td>2023-09-28T06:00:00+00:00</td>\n",
       "      <td>2023-10-02T00:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone RINA (2023) in the North Atla...</td>\n",
       "      <td>tropical cyclone, tropical storm, RINA, 2023, ...</td>\n",
       "      <td>20230928T060000-XYZ-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2023266N16323</td>\n",
       "      <td>Tropical Cyclone PHILIPPE</td>\n",
       "      <td>2023-09-23T06:00:00+00:00</td>\n",
       "      <td>2023-10-06T12:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone PHILIPPE (2023) in the North ...</td>\n",
       "      <td>tropical cyclone, tropical storm, PHILIPPE, 20...</td>\n",
       "      <td>20230923T060000-XYZ-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2023265N29284</td>\n",
       "      <td>Tropical Cyclone OPHELIA</td>\n",
       "      <td>2023-09-21T12:00:00+00:00</td>\n",
       "      <td>2023-09-24T18:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone OPHELIA (2023) in the North A...</td>\n",
       "      <td>tropical cyclone, tropical storm, OPHELIA, 202...</td>\n",
       "      <td>20230921T120000-USA-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>USA</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2023258N14318</td>\n",
       "      <td>Tropical Cyclone NIGEL</td>\n",
       "      <td>2023-09-15T06:00:00+00:00</td>\n",
       "      <td>2023-09-26T12:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone NIGEL (2023) in the North Atl...</td>\n",
       "      <td>tropical cyclone, hurricane, NIGEL, 2023, Nort...</td>\n",
       "      <td>20230915T060000-XYZ-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023251N15334</td>\n",
       "      <td>Tropical Cyclone MARGOT</td>\n",
       "      <td>2023-09-07T12:00:00+00:00</td>\n",
       "      <td>2023-09-18T18:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone MARGOT (2023) in the North At...</td>\n",
       "      <td>tropical cyclone, hurricane, MARGOT, 2023, Nor...</td>\n",
       "      <td>20230907T120000-XYZ-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023249N12320</td>\n",
       "      <td>Tropical Cyclone LEE</td>\n",
       "      <td>2023-09-05T12:00:00+00:00</td>\n",
       "      <td>2023-09-18T18:00:00+00:00</td>\n",
       "      <td>Tropical Cyclone LEE (2023) in the North Atlan...</td>\n",
       "      <td>tropical cyclone, hurricane, LEE, 2023, North ...</td>\n",
       "      <td>20230905T120000-CAN-NAT-MET-STO-TRO-001-GCDB</td>\n",
       "      <td>CAN</td>\n",
       "      <td>MH0057, nat-met-sto-tro, TC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                       title             start_datetime  \\\n",
       "58  2023321N15278  Tropical Cyclone NOT_NAMED  2023-11-16T18:00:00+00:00   \n",
       "57  2023297N11277  Tropical Cyclone NOT_NAMED  2023-10-23T12:00:00+00:00   \n",
       "56  2023292N13309      Tropical Cyclone TAMMY  2023-10-18T18:00:00+00:00   \n",
       "55  2023284N10330       Tropical Cyclone SEAN  2023-10-10T18:00:00+00:00   \n",
       "54  2023271N16316       Tropical Cyclone RINA  2023-09-28T06:00:00+00:00   \n",
       "53  2023266N16323   Tropical Cyclone PHILIPPE  2023-09-23T06:00:00+00:00   \n",
       "52  2023265N29284    Tropical Cyclone OPHELIA  2023-09-21T12:00:00+00:00   \n",
       "51  2023258N14318      Tropical Cyclone NIGEL  2023-09-15T06:00:00+00:00   \n",
       "50  2023251N15334     Tropical Cyclone MARGOT  2023-09-07T12:00:00+00:00   \n",
       "49  2023249N12320        Tropical Cyclone LEE  2023-09-05T12:00:00+00:00   \n",
       "\n",
       "                 end_datetime  \\\n",
       "58  2023-11-18T00:00:00+00:00   \n",
       "57  2023-10-24T12:00:00+00:00   \n",
       "56  2023-10-31T18:00:00+00:00   \n",
       "55  2023-10-16T18:00:00+00:00   \n",
       "54  2023-10-02T00:00:00+00:00   \n",
       "53  2023-10-06T12:00:00+00:00   \n",
       "52  2023-09-24T18:00:00+00:00   \n",
       "51  2023-09-26T12:00:00+00:00   \n",
       "50  2023-09-18T18:00:00+00:00   \n",
       "49  2023-09-18T18:00:00+00:00   \n",
       "\n",
       "                                          description  \\\n",
       "58  Tropical Cyclone NOT_NAMED (2023) in the North...   \n",
       "57  Tropical Cyclone NOT_NAMED (2023) in the North...   \n",
       "56  Tropical Cyclone TAMMY (2023) in the North Atl...   \n",
       "55  Tropical Cyclone SEAN (2023) in the North Atla...   \n",
       "54  Tropical Cyclone RINA (2023) in the North Atla...   \n",
       "53  Tropical Cyclone PHILIPPE (2023) in the North ...   \n",
       "52  Tropical Cyclone OPHELIA (2023) in the North A...   \n",
       "51  Tropical Cyclone NIGEL (2023) in the North Atl...   \n",
       "50  Tropical Cyclone MARGOT (2023) in the North At...   \n",
       "49  Tropical Cyclone LEE (2023) in the North Atlan...   \n",
       "\n",
       "                                             keywords  \\\n",
       "58  tropical cyclone, tropical depression, NOT_NAM...   \n",
       "57  tropical cyclone, tropical depression, NOT_NAM...   \n",
       "56  tropical cyclone, hurricane, TAMMY, 2023, Nort...   \n",
       "55  tropical cyclone, tropical storm, SEAN, 2023, ...   \n",
       "54  tropical cyclone, tropical storm, RINA, 2023, ...   \n",
       "53  tropical cyclone, tropical storm, PHILIPPE, 20...   \n",
       "52  tropical cyclone, tropical storm, OPHELIA, 202...   \n",
       "51  tropical cyclone, hurricane, NIGEL, 2023, Nort...   \n",
       "50  tropical cyclone, hurricane, MARGOT, 2023, Nor...   \n",
       "49  tropical cyclone, hurricane, LEE, 2023, North ...   \n",
       "\n",
       "                                  correlation_id country_codes  \\\n",
       "58  20231116T180000-XYZ-NAT-MET-STO-TRO-001-GCDB           XYZ   \n",
       "57  20231023T120000-NIC-NAT-MET-STO-TRO-001-GCDB           NIC   \n",
       "56  20231018T180000-ATG-NAT-MET-STO-TRO-001-GCDB           ATG   \n",
       "55  20231010T180000-XYZ-NAT-MET-STO-TRO-001-GCDB           XYZ   \n",
       "54  20230928T060000-XYZ-NAT-MET-STO-TRO-001-GCDB           XYZ   \n",
       "53  20230923T060000-XYZ-NAT-MET-STO-TRO-001-GCDB           XYZ   \n",
       "52  20230921T120000-USA-NAT-MET-STO-TRO-001-GCDB           USA   \n",
       "51  20230915T060000-XYZ-NAT-MET-STO-TRO-001-GCDB           XYZ   \n",
       "50  20230907T120000-XYZ-NAT-MET-STO-TRO-001-GCDB           XYZ   \n",
       "49  20230905T120000-CAN-NAT-MET-STO-TRO-001-GCDB           CAN   \n",
       "\n",
       "                   hazard_codes  \n",
       "58  MH0057, nat-met-sto-tro, TC  \n",
       "57  MH0057, nat-met-sto-tro, TC  \n",
       "56  MH0057, nat-met-sto-tro, TC  \n",
       "55  MH0057, nat-met-sto-tro, TC  \n",
       "54  MH0057, nat-met-sto-tro, TC  \n",
       "53  MH0057, nat-met-sto-tro, TC  \n",
       "52  MH0057, nat-met-sto-tro, TC  \n",
       "51  MH0057, nat-met-sto-tro, TC  \n",
       "50  MH0057, nat-met-sto-tro, TC  \n",
       "49  MH0057, nat-met-sto-tro, TC  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant information from event items into a DataFrame\n",
    "events_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"id\": item.id,\n",
    "            \"title\": item.properties.get(\"title\", \"\"),\n",
    "            \"start_datetime\": item.properties.get(\"start_datetime\", \"\"),\n",
    "            \"end_datetime\": item.properties.get(\"end_datetime\", \"\"),\n",
    "            \"description\": item.properties.get(\"description\", \"\"),\n",
    "            \"keywords\": \", \".join(item.properties.get(\"keywords\", [])),\n",
    "            \"correlation_id\": MontyExtension.ext(item).correlation_id,\n",
    "            \"country_codes\": \", \".join(MontyExtension.ext(item).country_codes or []),\n",
    "            \"hazard_codes\": \", \".join(MontyExtension.ext(item).hazard_codes or [])\n",
    "        }\n",
    "        for item in event_items\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Sort by start_datetime (descending)\n",
    "events_df = events_df.sort_values(by=\"start_datetime\", ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "events_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HazardDetail' object has no attribute 'pressure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract relevant information from hazard items into a DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m hazards_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m----> 3\u001b[0m     [\n\u001b[1;32m      4\u001b[0m         {\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39misoformat() \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mdatetime \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrelation_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mcorrelation_id,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mcountry_codes \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhazard_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_codes \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseverity_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mseverity_value \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseverity_unit\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mseverity_unit \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpressure\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mpressure \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpressure_unit\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mpressure_unit \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         }\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m hazard_items\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Sort by datetime (descending)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m hazards_df \u001b[38;5;241m=\u001b[39m hazards_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract relevant information from hazard items into a DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m hazards_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[1;32m      4\u001b[0m         {\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39misoformat() \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mdatetime \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: item\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrelation_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mcorrelation_id,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mcountry_codes \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhazard_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_codes \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseverity_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mseverity_value \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseverity_unit\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mseverity_unit \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m---> 14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpressure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mMontyExtension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhazard_detail\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpressure\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpressure_unit\u001b[39m\u001b[38;5;124m\"\u001b[39m: MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail\u001b[38;5;241m.\u001b[39mpressure_unit \u001b[38;5;28;01mif\u001b[39;00m MontyExtension\u001b[38;5;241m.\u001b[39mext(item)\u001b[38;5;241m.\u001b[39mhazard_detail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         }\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m hazard_items\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Sort by datetime (descending)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m hazards_df \u001b[38;5;241m=\u001b[39m hazards_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HazardDetail' object has no attribute 'pressure'"
     ]
    }
   ],
   "source": [
    "# Extract relevant information from hazard items into a DataFrame\n",
    "hazards_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"id\": item.id,\n",
    "            \"title\": item.properties.get(\"title\", \"\"),\n",
    "            \"datetime\": item.datetime.isoformat() if item.datetime else \"\",\n",
    "            \"description\": item.properties.get(\"description\", \"\"),\n",
    "            \"correlation_id\": MontyExtension.ext(item).correlation_id,\n",
    "            \"country_codes\": \", \".join(MontyExtension.ext(item).country_codes or []),\n",
    "            \"hazard_codes\": \", \".join(MontyExtension.ext(item).hazard_codes or []),\n",
    "            \"severity_value\": MontyExtension.ext(item).hazard_detail.severity_value if MontyExtension.ext(item).hazard_detail else None,\n",
    "            \"severity_unit\": MontyExtension.ext(item).hazard_detail.severity_unit if MontyExtension.ext(item).hazard_detail else None,\n",
    "            \"pressure\": MontyExtension.ext(item).hazard_detail.pressure if MontyExtension.ext(item).hazard_detail else None,\n",
    "            \"pressure_unit\": MontyExtension.ext(item).hazard_detail.pressure_unit if MontyExtension.ext(item).hazard_detail else None\n",
    "        }\n",
    "        for item in hazard_items\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Sort by datetime (descending)\n",
    "hazards_df = hazards_df.sort_values(by=\"datetime\", ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "hazards_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
