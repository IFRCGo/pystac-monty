{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USGS Earthquake Data with pystac-monty\n",
    "\n",
    "This notebook demonstrates how to use pystac-monty to process USGS earthquake data and visualize it using interactive maps. We'll:\n",
    "\n",
    "1. Fetch the latest major earthquakes from USGS\n",
    "2. Convert them to STAC items using pystac-monty\n",
    "3. Display events on an interactive map\n",
    "4. Allow selection of events to view related hazards and impacts\n",
    "5. Explore the Monty STAC model and its metadata\n",
    "\n",
    "Let's begin by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytz\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfolium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarkerCluster\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clear_output, display\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpystac_monty\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MontyExtension\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Visualization libraries\n",
    "import pandas as pd\n",
    "\n",
    "# STAC and pystac-monty\n",
    "import pytz\n",
    "import requests\n",
    "\n",
    "from pystac_monty.extension import MontyExtension\n",
    "from pystac_monty.geocoding import WorldAdministrativeBoundariesGeocoder\n",
    "from pystac_monty.sources.usgs import USGSDataSource, USGSTransformer\n",
    "\n",
    "# Import STAC helper functions\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from stac_helpers import (\n",
    "    check_stac_api_availability,\n",
    "    check_collection_exists,\n",
    "    create_collection_from_file,\n",
    "    create_collection_fallback,\n",
    "    add_items_to_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetch Recent Major Earthquakes from USGS\n",
    "\n",
    "Let's fetch earthquakes with magnitude 5.5+ from the past 10 days using the USGS API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define USGS API endpoint for fetching earthquake data\n",
    "def fetch_usgs_earthquakes(min_magnitude=5.5, days=60):\n",
    "    \"\"\"\n",
    "    Fetch earthquake data from USGS API\n",
    "\n",
    "    Parameters:\n",
    "    - min_magnitude: Minimum magnitude to filter earthquakes (default: 4.5)\n",
    "    - days: Number of days to look back (default: 30)\n",
    "\n",
    "    Returns:\n",
    "    - List of earthquake data as dictionaries\n",
    "    \"\"\"\n",
    "    # Calculate the start time (days ago from now)\n",
    "    start_time = datetime.now() - timedelta(days=days)\n",
    "    start_time_str = start_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "    # USGS earthquake API endpoint\n",
    "    url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\"format\": \"geojson\", \"starttime\": start_time_str, \"minmagnitude\": min_magnitude, \"orderby\": \"time\"}\n",
    "\n",
    "    # Make the request to the USGS API\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    print(f\"Found {len(data['features'])} earthquakes with magnitude {min_magnitude}+ in the last {days} days\")\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fetch recent major earthquakes\n",
    "earthquake_data = fetch_usgs_earthquakes(min_magnitude=5.5, days=60)\n",
    "earthquake_features = earthquake_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant information into a DataFrame\n",
    "earthquakes_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"id\": eq[\"id\"],\n",
    "            \"title\": eq[\"properties\"][\"title\"],\n",
    "            \"time\": datetime.fromtimestamp(eq[\"properties\"][\"time\"] / 1000, pytz.UTC),\n",
    "            \"magnitude\": eq[\"properties\"][\"mag\"],\n",
    "            \"place\": eq[\"properties\"][\"place\"],\n",
    "            \"longitude\": eq[\"geometry\"][\"coordinates\"][0],\n",
    "            \"latitude\": eq[\"geometry\"][\"coordinates\"][1],\n",
    "            \"depth\": eq[\"geometry\"][\"coordinates\"][2],\n",
    "            \"tsunami\": bool(eq[\"properties\"].get(\"tsunami\")),\n",
    "            \"felt\": eq[\"properties\"].get(\"felt\") or 0,\n",
    "        }\n",
    "        for eq in earthquake_features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Sort by magnitude (descending)\n",
    "earthquakes_df = earthquakes_df.sort_values(by=\"magnitude\", ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "earthquakes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Synthetic STAC Items\n",
    "\n",
    "Let's create synthetic STAC items from the earthquake data using the pystac-monty extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the geocoder\n",
    "geocoder = WorldAdministrativeBoundariesGeocoder(\"../tests/data-files/world-administrative-boundaries.fgb\")\n",
    "\n",
    "# Create a list to store all synthetic STAC items\n",
    "all_stac_items = []\n",
    "\n",
    "# Loop through the earthquake data and create synthetic STAC items\n",
    "for earthquake in earthquakes_df.to_dict(orient=\"records\"):\n",
    "    # Define the USGS API endpoint for fetching event detailed geojson\n",
    "    event_url = f\"https://earthquake.usgs.gov/earthquakes/feed/v1.0/detail/{earthquake['id']}.geojson\"\n",
    "\n",
    "    # Get the event data\n",
    "    event_data = requests.get(event_url).text\n",
    "    event_data_json = json.loads(event_data)\n",
    "\n",
    "    # Find the losses data in the event data\n",
    "    try:\n",
    "        losses_data_url = event_data_json[\"properties\"][\"products\"][\"losspager\"][0][\"contents\"][\"json/losses.json\"][\"url\"]\n",
    "        losses_data = requests.get(losses_data_url).text\n",
    "    except KeyError:\n",
    "        losses_data = None\n",
    "\n",
    "    # Setup the transformer\n",
    "    data_source = USGSDataSource(event_url, event_data, losses_data)\n",
    "    transformer = USGSTransformer(data_source, geocoder)\n",
    "\n",
    "    # Create the synthetic STAC item\n",
    "    items = transformer.make_items()\n",
    "    all_stac_items.extend(items)\n",
    "\n",
    "# Create synthetic STAC items\n",
    "print(f\"Created {len(all_stac_items)} STAC items from {len(earthquake_features)} earthquakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the STAC items by role\n",
    "event_items = []\n",
    "hazard_items = []\n",
    "impact_items = []\n",
    "\n",
    "for item in all_stac_items:\n",
    "    roles = item.properties.get(\"roles\", [])\n",
    "    if \"event\" in roles:\n",
    "        event_items.append(item)\n",
    "    elif \"hazard\" in roles:\n",
    "        hazard_items.append(item)\n",
    "    elif \"impact\" in roles:\n",
    "        impact_items.append(item)\n",
    "\n",
    "print(f\"Events: {len(event_items)}, Hazards: {len(hazard_items)}, Impacts: {len(impact_items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading STAC Items into a STAC API using the Transaction API\n",
    "\n",
    "Now that we have created STAC items from the USGS earthquake data, let's load them into a STAC API using the transaction API. The transaction API allows us to create, update, and delete STAC items in a STAC API.\n",
    "\n",
    "We'll use the predefined collections from the monty-stac-extension examples folder:\n",
    "- usgs-events: For event items\n",
    "- usgs-hazards: For hazard items\n",
    "- usgs-impacts: For impact items\n",
    "\n",
    "If these collections don't exist in the STAC API, we'll create them based on the predefined collection definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for STAC API interaction\n",
    "import requests\n",
    "import json\n",
    "import pystac\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the STAC API endpoint\n",
    "# Replace with your actual STAC API endpoint\n",
    "stac_api_url = \"https://montandon-eoapi-stage.ifrc.org/stac\"\n",
    "\n",
    "# Define the collection IDs for each type of item\n",
    "# These match the predefined collections in monty-stac-extension/examples\n",
    "event_collection_id = \"usgs-events\"\n",
    "hazard_collection_id = \"usgs-hazards\"\n",
    "impact_collection_id = \"usgs-impacts\"\n",
    "\n",
    "# Define paths to the predefined collection definitions\n",
    "event_collection_path = \"../monty-stac-extension/examples/usgs-events/usgs-events.json\"\n",
    "hazard_collection_path = \"../monty-stac-extension/examples/usgs-hazards/usgs-hazards.json\"\n",
    "impact_collection_path = \"../monty-stac-extension/examples/usgs-impacts/usgs-impacts.json\"\n",
    "\n",
    "# Check if the STAC API is available\n",
    "api_available = check_stac_api_availability(stac_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the collections exist and create them if they don't\n",
    "if api_available:\n",
    "    # Check and create event collection if needed\n",
    "    event_collection_exists = check_collection_exists(stac_api_url, event_collection_id)\n",
    "    if not event_collection_exists:\n",
    "        print(f\"\\nAttempting to create collection '{event_collection_id}'...\")\n",
    "        event_collection_created = create_collection_from_file(stac_api_url, event_collection_path)\n",
    "        if not event_collection_created:\n",
    "            print(\"Trying fallback method to create event collection...\")\n",
    "            event_collection_created = create_collection_fallback(\n",
    "                stac_api_url, \n",
    "                event_collection_id, \n",
    "                \"USGS Earthquake events processed with pystac-monty\",\n",
    "                [\"event\", \"source\"]\n",
    "            )\n",
    "        event_collection_exists = event_collection_created\n",
    "    \n",
    "    # Check and create hazard collection if needed\n",
    "    hazard_collection_exists = check_collection_exists(stac_api_url, hazard_collection_id)\n",
    "    if not hazard_collection_exists:\n",
    "        print(f\"\\nAttempting to create collection '{hazard_collection_id}'...\")\n",
    "        hazard_collection_created = create_collection_from_file(stac_api_url, hazard_collection_path)\n",
    "        if not hazard_collection_created:\n",
    "            print(\"Trying fallback method to create hazard collection...\")\n",
    "            hazard_collection_created = create_collection_fallback(\n",
    "                stac_api_url, \n",
    "                hazard_collection_id, \n",
    "                \"USGS Earthquake hazards processed with pystac-monty\",\n",
    "                [\"hazard\", \"source\"]\n",
    "            )\n",
    "        hazard_collection_exists = hazard_collection_created\n",
    "    \n",
    "    # Check and create impact collection if needed\n",
    "    impact_collection_exists = check_collection_exists(stac_api_url, impact_collection_id)\n",
    "    if not impact_collection_exists:\n",
    "        print(f\"\\nAttempting to create collection '{impact_collection_id}'...\")\n",
    "        impact_collection_created = create_collection_from_file(stac_api_url, impact_collection_path)\n",
    "        if not impact_collection_created:\n",
    "            print(\"Trying fallback method to create impact collection...\")\n",
    "            impact_collection_created = create_collection_fallback(\n",
    "                stac_api_url, \n",
    "                impact_collection_id, \n",
    "                \"USGS Earthquake impacts processed with pystac-monty\",\n",
    "                [\"impact\", \"source\"]\n",
    "            )\n",
    "        impact_collection_exists = impact_collection_created\n",
    "    \n",
    "    if not (event_collection_exists and hazard_collection_exists and impact_collection_exists):\n",
    "        print(\"\\nWarning: One or more collections could not be created in the STAC API.\")\n",
    "        print(\"Some items may not be added to the STAC API.\")\n",
    "else:\n",
    "    print(\"STAC API is not available. Skipping collection checks and creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the items to their respective collections if the API is available\n",
    "if api_available:\n",
    "    if event_collection_exists:\n",
    "        print(\"Adding event items to the collection...\")\n",
    "        event_success, event_failed = add_items_to_collection(stac_api_url, event_collection_id, event_items)\n",
    "    else:\n",
    "        print(\"Skipping adding event items because the collection doesn't exist\")\n",
    "        event_success, event_failed = 0, len(event_items)\n",
    "    \n",
    "    if hazard_collection_exists:\n",
    "        print(\"\\nAdding hazard items to the collection...\")\n",
    "        hazard_success, hazard_failed = add_items_to_collection(stac_api_url, hazard_collection_id, hazard_items)\n",
    "    else:\n",
    "        print(\"Skipping adding hazard items because the collection doesn't exist\")\n",
    "        hazard_success, hazard_failed = 0, len(hazard_items)\n",
    "    \n",
    "    if impact_collection_exists:\n",
    "        print(\"\\nAdding impact items to the collection...\")\n",
    "        impact_success, impact_failed = add_items_to_collection(stac_api_url, impact_collection_id, impact_items)\n",
    "    else:\n",
    "        print(\"Skipping adding impact items because the collection doesn't exist\")\n",
    "        impact_success, impact_failed = 0, len(impact_items)\n",
    "    \n",
    "    total_success = event_success + hazard_success + impact_success\n",
    "    total_failed = event_failed + hazard_failed + impact_failed\n",
    "    \n",
    "    print(f\"\\nSummary: Added {total_success} items successfully, {total_failed} items failed\")\n",
    "else:\n",
    "    print(\"Skipping adding items to collections because the API is not available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
